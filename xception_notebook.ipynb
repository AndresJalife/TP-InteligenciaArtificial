{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se utilizó de guía principalmente:\n",
    "# https://www.tensorflow.org/tutorials/images/classification\n",
    "#Y de forma paralela:\n",
    "# https://keras.io/examples/vision/image_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atención, bajar dataset previamente: https://www.kaggle.com/miljan/stanford-dogs-dataset-traintest\n",
    "#extraerlo, y que la carpeta resultante quede en el mismo directorio que el notebook.\n",
    "train_dir = 'archive/cropped/train'\n",
    "test_dir = 'archive/cropped/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9360003137243149933\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test GPU\n",
    "tf.config.list_physical_devices('GPU')\n",
    "#Si aca no les aparece una lista vacia, y les corren las cosas sin errores, en particular sin este:\n",
    "# \"CUDA runtime implicit initialization on GPU:0 failed.\" entonces les anda la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test GPU\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-807d55075008>:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test GPU\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "#Version tensorflow 2.3 como mínimo para tf.keras.preprocessing.image_dataset_from_directory (o instalar tf-nightly a la par)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8040 images belonging to 120 classes.\n",
      "Found 3960 images belonging to 120 classes.\n",
      "Found 8580 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "#Parte mia\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator( \n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n",
    "    rotation_range=40,\n",
    "    zoom_range = 0.1,\n",
    "    rescale=1./255,\n",
    "    validation_split=0.33)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42, \n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "# Valid generator\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42, \n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Test generator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "optimizer = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 55s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#Xception model con un par de cambios \n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "base_model = Xception(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- \n",
    "predictions = layers.Dense(120, activation='softmax')(x)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional Xception layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# this is the model we will train\n",
    "xception = Model(inputs=base_model.input, outputs=predictions)\n",
    "xception.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 934s 7s/step - loss: 2.0782 - accuracy: 0.5229 - val_loss: 0.9376 - val_accuracy: 0.7275\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 892s 7s/step - loss: 0.7727 - accuracy: 0.7726 - val_loss: 0.8476 - val_accuracy: 0.7426\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 831s 7s/step - loss: 0.6818 - accuracy: 0.7885 - val_loss: 0.9000 - val_accuracy: 0.7339\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 829s 7s/step - loss: 0.5830 - accuracy: 0.8138 - val_loss: 0.8717 - val_accuracy: 0.7480\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 934s 7s/step - loss: 0.5493 - accuracy: 0.8220 - val_loss: 0.8517 - val_accuracy: 0.7579\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 948s 8s/step - loss: 0.5232 - accuracy: 0.8312 - val_loss: 0.8901 - val_accuracy: 0.7590\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 924s 7s/step - loss: 0.4566 - accuracy: 0.8508 - val_loss: 0.8701 - val_accuracy: 0.7582\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 922s 7s/step - loss: 0.4486 - accuracy: 0.8537 - val_loss: 0.8900 - val_accuracy: 0.7628\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 945s 8s/step - loss: 0.4153 - accuracy: 0.8619 - val_loss: 0.9261 - val_accuracy: 0.7597\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 966s 8s/step - loss: 0.3900 - accuracy: 0.8694 - val_loss: 0.9481 - val_accuracy: 0.7664\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fe9fcc7808>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xception.fit(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    callbacks=[learning_rate_reduction]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5536444187164307 0.8506296873092651\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "loss, acc = xception.evaluate_generator(generator=test_generator, steps=STEP_SIZE_TEST, verbose=0)\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Guardo el modelo entrenado\n",
    "xception_model_json = xception.to_json()\n",
    "with open(\"xcept_model.json\", \"w\") as json_file:\n",
    "    json_file.write(xception_model_json)\n",
    "# serialize weights to HDF5\n",
    "xception.save_weights(\"weight_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 85.06%\n"
     ]
    }
   ],
   "source": [
    "#Para cargar el modelo entrenado\n",
    "# load json and create model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "json_file = open('xcept_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "xception_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "xception_model.load_weights(\"weight_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilacion del modelo loadeado\n",
    "xception_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "score = xception_model.evaluate(test_generator, steps=STEP_SIZE_TEST, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (xception_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xception_model.predict(test_generator,steps = STEP_SIZE_TEST, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataGenerator' object has no attribute 'class_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-ae5711059129>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdogs_breeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdogs_breeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDataGenerator' object has no attribute 'class_names'"
     ]
    }
   ],
   "source": [
    "dogs_breeds = test_datagen.class_names\n",
    "print(dogs_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras' has no attribute 'np_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-4406a9f8db03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnp_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobas_to_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras' has no attribute 'np_utils'"
     ]
    }
   ],
   "source": [
    "tf.keras.np_utils.probas_to_classes(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 119, 119, 119], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes = predictions.argmax(axis=-1)\n",
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8580 files belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "#Creo train_ds solamente para tener las classnames\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  test_dir)\n",
    "breeds = test_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_class = []\n",
    "count = 0\n",
    "for pred in y_classes:\n",
    "    results_by_class.append((breeds[pred],count))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(\"archive/cropped/test\")\n",
    "all_filenames = []\n",
    "for breed in breeds:\n",
    "    pictures = os.listdir(\"archive/cropped/test/\" + breed)\n",
    "    for pic in pictures:\n",
    "        all_filenames.append((pic,breed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "pos_selected = 29\n",
    "Image(filename= 'archive/cropped/test/'+ all_filenames[pos_selected][1] + '/'+all_filenames[pos_selected][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: n02099849-Chesapeake_Bay_retriever\n",
      "Raza Verdadera: n02085620-Chihuahua\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicción: \" + results_by_class[pos_selected][0] + \"\\nRaza Verdadera: \" + all_filenames[pos_selected][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
